{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0UK9tPKIlTF"
      },
      "source": [
        "# Keras OCR 공개구현체의 Detector(CRAFT모델) Fine-tuning 실습\n",
        "\n",
        "이 예제에서는 본인만의 데이터셋을 사용해서, OCR 공개구현체에서 문자 위치를 찾는 Detector 기능을 Fine-tuning하는 실습을 수행합니다.\n",
        "\n",
        "여기 예제에서는 [여기](https://rrc.cvc.uab.es/?ch=1&com=downloads)에서 다운로드 받을 수 있는 ICDAR2013 문자인식용 데이터셋으로 Fine-tuning을 수행합니다.\n",
        "\n",
        "Copyright: https://keras-ocr.readthedocs.io/en/latest/examples/fine_tuning_detector.html 의 공개구현체를 교육 목적에 맞게 수정 (2023.5.11, 김상호)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(2024.11.18)**  tf.keras.callbacks.ModelCheckpoint() 함수에서 ValueError 발생하여 [링크](https://github.com/pythonlessons/mltu/issues/48) 의 방법에 따라 'save_weights_only=True'를 argument에 추가하고, checkpoint file의 이름 수정. model.fit() 함수의 arguments 중에서 workers도 blank 처리함.\n",
        "\n",
        "**(2025.05.12)** imgaug 라이브러리와의 호환성 이슈때문에 numpy==1.25.0으로 다운그레이드"
      ],
      "metadata": {
        "id": "RNn-PdFMO3iO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "1x-mC4wxPOLG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(2025.05.12)** imgaug 라이브러리와의 호환성 이슈때문에 numpy==1.25.0으로 다운그레이드"
      ],
      "metadata": {
        "id": "uIillreRPWU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.25.0\n"
      ],
      "metadata": {
        "id": "QHtF2qADLbC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kKzHd0h5bA9"
      },
      "source": [
        "Keras OCR을 설치합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjLTQeJHLUXw"
      },
      "outputs": [],
      "source": [
        "pip install keras_ocr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "c-MpWv1vSTxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-arRYFtMtQx"
      },
      "source": [
        "OCR 라이브러리를 비롯해 다른 필요한 라이브러리들을 설치합니다.\n",
        "\n",
        "'data_dir' 변수는 checkpoint file을 담고 있는 폴더로 지정합니다. (google drive의 폴더 위치)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9VN9EmkyIlTI"
      },
      "outputs": [],
      "source": [
        "data_dir = '/content/drive/MyDrive/object_detection'\n",
        "\n",
        "import os\n",
        "import math\n",
        "import imgaug\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn.model_selection\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras_ocr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMxjCloxM8pT"
      },
      "source": [
        "Keras에 내장된 ICDAR2013 문자인식용 데이터셋(이미지+문자 위치정보)을 읽어옵니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODdEu1WoIlTM"
      },
      "outputs": [],
      "source": [
        "dataset = keras_ocr.datasets.get_icdar_2013_detector_dataset(\n",
        "    cache_dir='.',\n",
        "    skip_illegible=False\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dataset을 인쇄해서 어떤 형태로 구성되어 있는지 분석해봅니다.\n",
        "\n",
        "공개구현체를 이용하기 위해서는, 본인의 데이터셋(이미지+문자위치 박스 정보)을 읽어와서 분석된 dataset과 같은 형태로 가공해야 합니다.\n",
        "\n",
        "구체적으로는, dataset 형태를 분석해서, 위의 keras_ocr 라이브러리에서 내장 데이터셋을 읽어오는 get_icdar_2013_detector_dataset()함수와 유사하게 dataset을 return해주는 새로운 함수 get_mydata_detector_dataset() 함수를 만들어야 합니다."
      ],
      "metadata": {
        "id": "93V2gWbmtsCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "wycAcaJ5uCmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMUf85rF_5jX"
      },
      "outputs": [],
      "source": [
        "dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0][1]"
      ],
      "metadata": {
        "id": "WSNHM1mQuJ6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0][1][0]"
      ],
      "metadata": {
        "id": "VqMQUrx1uNUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0][1][0][0]"
      ],
      "metadata": {
        "id": "cgMbByoVuUki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0][1][0][0][0]"
      ],
      "metadata": {
        "id": "GKC5hmzQucVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ICDAR2013 dataset이 아니라, 본인의 데이터셋을 읽어와서 detector를 학습하기 위해서는 여기 위치에서 2가지를 해야 합니다.\n",
        "\n",
        "1. 본인만의 데이터셋을 업로드해서 unzip하고, training imge와 ground truth 파일을 ICDAR2013 dataset과 비교 (특히, ground truth 파일의 내용 비교 필요)\n",
        "2. get_icdar_2013_detector_dataset()함수와 유사하게 dataset을 return해주는 새로운 함수 get_mydata_detector_dataset() 함수를 define (ground truth file에 들어가 있는 내용을 해석해서, 위에서 분석한 dataset 형식으로 가공하도록)\n",
        "\n"
      ],
      "metadata": {
        "id": "uYhiYLjDunBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mydata_detector_dataset(cache_dir=None, skip_illegible=False):\n",
        "  ..."
      ],
      "metadata": {
        "id": "VupwdxOQujHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = get_mydata_detector_dataset(cache_dir='.')"
      ],
      "metadata": {
        "id": "pV9MI5PgweUW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "dataset이 의도했던 포맷으로 나오는지 확인합니다."
      ],
      "metadata": {
        "id": "NzjPTo_gwpkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "nslBjR7zwlLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6w4KNqp-NSlm"
      },
      "source": [
        "읽어온 데이터셋은 Training:Validation = 80%:20%로 분할하고, 아래의 전처리를 수행합니다. 단, Validation Images는 augmentation은 적용하지 않습니다.\n",
        "\n",
        "1.   Augmentation (random scaling/rotation/blurring/multiplication)\n",
        "2.   이미지를 640*480 사이즈로 변경"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QaRJ4t1rIlTO"
      },
      "outputs": [],
      "source": [
        "train, validation = sklearn.model_selection.train_test_split(\n",
        "    dataset, train_size=0.8, random_state=42\n",
        ")\n",
        "augmenter = imgaug.augmenters.Sequential([\n",
        "    imgaug.augmenters.Affine(\n",
        "      scale=(1.0, 1.2),\n",
        "      rotate=(-5, 5)\n",
        "    ),\n",
        "    imgaug.augmenters.GaussianBlur(sigma=(0, 0.5)),\n",
        "    imgaug.augmenters.Multiply((0.8, 1.2), per_channel=0.2)\n",
        "])\n",
        "generator_kwargs = {'width': 640, 'height': 480}\n",
        "training_image_generator = keras_ocr.datasets.get_detector_image_generator(\n",
        "    labels=train,\n",
        "    augmenter=augmenter,\n",
        "    **generator_kwargs\n",
        ")\n",
        "validation_image_generator = keras_ocr.datasets.get_detector_image_generator(\n",
        "    labels=validation,\n",
        "    **generator_kwargs\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isc_YFZGIlTQ"
      },
      "source": [
        "제대로 training용 dataset이 준비되었는지 Sanity check 목적으로, 입력 이미지중 하나를 문자위치 박스와 함께 화면에 보여줍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYA-1IxgIlTR"
      },
      "outputs": [],
      "source": [
        "image, lines, confidence = next(training_image_generator)\n",
        "canvas = keras_ocr.tools.drawBoxes(image=image, boxes=lines, boxes_format='lines')\n",
        "plt.imshow(canvas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eULWLkAyIlTU"
      },
      "source": [
        "Detector 모델을 Keras OCR 라이브러리를 사용해서 build하는데, 이때 Detector 모델의 초기 weights는 CRAFT모델의 pre-trained weights를 자동으로 읽어옵니다.\n",
        "\n",
        "그 후에, 1000번의 epoch동안 fine-tuning 학습을 수행하면서, 매 학습차수(epoch)마다 Keras의 callback 라이브러리를 사용하여 아래 항목들을 수행합니다.\n",
        "(만일, 10번으로 나눠서 학습을 하고싶다면, epochs 숫자를 100으로 줄여서 학습을 하고, 다시 학습을 시작할 때에 h5 weights file을 Colab에 업로드하고 아래 학습을 시작하는 방식으로 이어서 학습합니다)\n",
        "\n",
        "1.   손실함수가 줄어들지 않으면 1000번 epoch을 모두 실행하기 이전에 조기 종료시키는 early stopping (학습이 충분하게 이루어지지 않을 경우, comment처리하거나 patience값을 키움)\n",
        "2.   학습 과정을 지정된 csv 파일로 기록\n",
        "3.  학습된 weights를 지정된 checkpoint파일에 기록\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "detector = keras_ocr.detection.Detector()\n",
        "# if any, load the detector model weights\n",
        "model_weights = os.path.join(data_dir,'detector_mydata.h5')\n",
        "if os.path.isfile(model_weights) == True:\n",
        "  detector.model.load_weights(model_weights)\n",
        "  print(model_weights,': loaded successfully!')"
      ],
      "metadata": {
        "id": "nbB4k_rUxsi7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0aa599f-0bd0-47c3-c63f-c3be151fac00"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking for /root/.keras-ocr/craft_mlt_25k.h5\n",
            "Downloading /root/.keras-ocr/craft_mlt_25k.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(2024.11.18)**  tf.keras.callbacks.ModelCheckpoint() 함수에서 ValueError 발생하여 [링크](https://github.com/pythonlessons/mltu/issues/48) 의 방법에 따라 'save_weights_only=True'를 argument에 추가하고, checkpoint file의 이름 수정. model.fit() 함수의 arguments 중에서 workers도 blank 처리함."
      ],
      "metadata": {
        "id": "W2uTzO2VTWnY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGDTmDOuIlTV"
      },
      "outputs": [],
      "source": [
        "# Run the re-training\n",
        "batch_size = 1\n",
        "training_generator, validation_generator = [\n",
        "    detector.get_batch_generator(\n",
        "        image_generator=image_generator, batch_size=batch_size\n",
        "    ) for image_generator in\n",
        "    [training_image_generator, validation_image_generator]\n",
        "]\n",
        "detector.model.fit(\n",
        "    training_generator,\n",
        "    steps_per_epoch=math.ceil(len(train) / batch_size),\n",
        "    epochs=2,\n",
        "#    workers=0,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(restore_best_weights=True, patience=5),\n",
        "        tf.keras.callbacks.CSVLogger(os.path.join(data_dir, 'detector_icdar2013.csv')),\n",
        "        tf.keras.callbacks.ModelCheckpoint(save_weights_only=True, filepath=os.path.join(data_dir, 'detector_icdar2013.weights.h5'))\n",
        "    ],\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=math.ceil(len(validation) / batch_size)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/drive/MyDrive/object_detection/detector_icdar2013.weights.h5 /content/drive/MyDrive/object_detection/detector_icdar2013.weights.h5.20250513"
      ],
      "metadata": {
        "id": "QulT0yQOHRdh"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoqIh7YvSw6e"
      },
      "source": [
        "Detector의 fine-tuning 학습이 끝나면, 학습과정을 담고 있는 csv 로그 파일과, 학습결과 weights를 담고 있는 체크포인트 파일을 본인의 PC로 다운로드 받습니다. 아래 code에서 파일명은 위에서 지정된 checkpoint file의 위치로 수정해야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czkWdPX7TmXK"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/detector_icdar2013.csv\")\n",
        "files.download(\"/content/detector_icdar2013.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dpstx2XgCbGT"
      },
      "source": [
        "---\n",
        "\n",
        "### 학습된 Weights로 Validation 데이터를 추론해보기\n",
        "\n",
        "위의 100번 epoch 실행을 10번 반복 수행해서, 총 1000번 epoch만큼 학습이 완료된 'detector_mydata.h5' 파일을 Colab에 업로드해서 detection test를 수행해 봅시다.\n",
        "\n",
        "아래 셀을 실행하면, 모든 validation 데이터셋에 대해 detection을 수행하고, 문자 위치 박스가 표시된 결과 이미지를 output_folder에 저장합니다.\n",
        "\n",
        "학습을 몇번만 진행한 것과 충분히 학습한 Detector의 추론 성능을 아래와 같이 비교해보세요.\n",
        "\n",
        "1. 먼저, 위에서 학습을 진행하지 않거나 몇번 epoch만 학습을 진행하고 중단한 후에, 아래의 셀을 실행해서 추론 성능을 test합니다.\n",
        "2. 다음에, 1000번 학습이 완료된 weights 파일('detector.mydata.h5')을 업로드하고, 위로 돌아가서 detector를 다시 build하고, 아래의 셀을 실행해서 추론 성능을 test합니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir mydata_detection_result"
      ],
      "metadata": {
        "id": "RjM2_MUh0REI"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import imageio\n",
        "import cv2\n",
        "\n",
        "output_folder = 'mydata_detection_result'\n",
        "\n",
        "for image_path, _, _ in validation:\n",
        "  image = keras_ocr.tools.read(image_path)\n",
        "\n",
        "  output_image_path = os.path.join(output_folder, image_path.split('/')[-1])\n",
        "\n",
        "  # detector prediction\n",
        "  pred_boxes = detector.detect(np.expand_dims(image, axis=0))\n",
        "\n",
        "  for each_pred in pred_boxes[0]:\n",
        "    left, top = each_pred[0]\n",
        "    right, bottom = each_pred[2]\n",
        "    canvas = cv2.rectangle(image, (int(left), int(top)), (int(right), int(bottom)), (0,255,0), 3)\n",
        "\n",
        "  imageio.imwrite(output_image_path, canvas)\n",
        "  print(output_image_path + ' saved!' )"
      ],
      "metadata": {
        "id": "ru3tVUAu0eD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Detection 추론 결과 폴더를 압축하고, 내 PC로 다운로드 받습니다."
      ],
      "metadata": {
        "id": "-SAanEr__kje"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/mydata_detection_result.zip /content/mydata_detection_result\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"/content/mydata_detection_result.zip\")"
      ],
      "metadata": {
        "id": "Uo-SCKik_o9h"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}