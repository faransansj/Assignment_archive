{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 7.1 - MNIST Classification using CNN with TensorBoard\n",
        "\n",
        "## 순서\n",
        "1. 라이브러리 임포트 및 TensorBoard 설정\n",
        "2. MNIST 데이터 불러오기 및 전처리\n",
        "3. CNN 모델 정의 (tf.keras.Model)\n",
        "4. 손실함수, 옵티마이저, 정확도 함수 정의\n",
        "5. TensorBoard 로그 생성\n",
        "6. train_step 함수에서 텐서보드 로그 기록\n",
        "7. 학습 루프 (Mini-batch)\n",
        "8. 최종 테스트 정확도 기록 및 TensorBoard에서 시각화\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost/"
        },
        "executionInfo": {},
        "id": "import-libraries"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.10.1\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import datetime, os\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. MNIST 데이터 불러오기 및 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "executionInfo": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 784)\n",
            "y_train shape: (60000, 10)\n"
          ]
        }
      ],
      "source": [
        "# MNIST 데이터를 다운로드 하고, 정규화\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test  = x_test.astype('float32')\n",
        "\n",
        "x_train = x_train.reshape([-1, 784])\n",
        "x_test  = x_test.reshape([-1, 784])\n",
        "\n",
        "x_train = x_train / 255.\n",
        "x_test  = x_test / 255.\n",
        "\n",
        "y_train = tf.one_hot(y_train, depth=10)\n",
        "y_test  = tf.one_hot(y_test,  depth=10)\n",
        "\n",
        "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_data = train_data.repeat().shuffle(60000).batch(50)\n",
        "train_data_iter = iter(train_data)\n",
        "\n",
        "print(f\"x_train shape: {x_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. CNN 모델 정의 (tf.keras.Model 사용)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "executionInfo": {}
      },
      "outputs": [],
      "source": [
        "class CNN(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # 첫 번째 Convolution Layer: 5x5 Kernel, 32개 Filter\n",
        "        self.conv_layer_1 = tf.keras.layers.Conv2D(\n",
        "            filters=32, kernel_size=5, strides=1, padding='same', activation='relu')\n",
        "        self.pool_layer_1 = tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=2)\n",
        "\n",
        "        # 두 번째 Convolution Layer: 5x5 Kernel, 64개 Filter\n",
        "        self.conv_layer_2 = tf.keras.layers.Conv2D(\n",
        "            filters=64, kernel_size=5, strides=1, padding='same', activation='relu')\n",
        "        self.pool_layer_2 = tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=2)\n",
        "\n",
        "        # Flatten + Fully connected\n",
        "        self.flatten_layer = tf.keras.layers.Flatten()\n",
        "        self.fc_layer_1    = tf.keras.layers.Dense(1024, activation='relu')\n",
        "        self.output_layer  = tf.keras.layers.Dense(10, activation=None)\n",
        "\n",
        "    def call(self, x):\n",
        "        # x: (batch, 784) -> reshape to (batch,28,28,1)\n",
        "        x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
        "\n",
        "        h_conv1 = self.conv_layer_1(x_image)   # -> (batch, 28,28,32)\n",
        "        h_pool1 = self.pool_layer_1(h_conv1)   # -> (batch, 14,14,32)\n",
        "\n",
        "        h_conv2 = self.conv_layer_2(h_pool1)   # -> (batch, 14,14,64)\n",
        "        h_pool2 = self.pool_layer_2(h_conv2)   # -> (batch, 7,7,64)\n",
        "\n",
        "        h_pool2_flat = self.flatten_layer(h_pool2)  # -> (batch, 7*7*64=3136)\n",
        "        h_fc1 = self.fc_layer_1(h_pool2_flat)       # -> (batch, 1024)\n",
        "\n",
        "        logits = self.output_layer(h_fc1)           # -> (batch, 10)\n",
        "        y_pred = tf.nn.softmax(logits, axis=1)\n",
        "        return y_pred, logits\n",
        "\n",
        "# 모델 인스턴스 생성\n",
        "CNN_model = CNN()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 손실함수, 옵티마이저, 정확도 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "executionInfo": {}
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def cross_entropy_loss(logits, y):\n",
        "    return tf.reduce_mean(\n",
        "        tf.nn.softmax_cross_entropy_with_logits(\n",
        "            logits=logits, labels=y)\n",
        "    )\n",
        "\n",
        "optimizer = tf.optimizers.Adam(1e-4)\n",
        "\n",
        "@tf.function\n",
        "def compute_accuracy(y_pred, y):\n",
        "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. TensorBoard 로그 디렉토리 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "executionInfo": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_log_dir: tensorboard_log\\train\n",
            "test_log_dir : tensorboard_log\\test\n"
          ]
        }
      ],
      "source": [
        "log_dir = \"tensorboard_log\"  # 로그 저장 경로\n",
        "train_log_dir = os.path.join(log_dir, \"train\")\n",
        "test_log_dir  = os.path.join(log_dir, \"test\")\n",
        "\n",
        "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
        "test_summary_writer  = tf.summary.create_file_writer(test_log_dir)\n",
        "\n",
        "print(f\"train_log_dir: {train_log_dir}\")\n",
        "print(f\"test_log_dir : {test_log_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. train_step 함수에서 텐서보드 로그 기록"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "executionInfo": {}
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(model, x, y, step):\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred, logits = model(x)\n",
        "        loss_value = cross_entropy_loss(logits, y)\n",
        "\n",
        "    gradients = tape.gradient(loss_value, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    # 텐서보드에 loss 기록\n",
        "    with train_summary_writer.as_default():\n",
        "        tf.summary.scalar('training_loss', loss_value, step=step)\n",
        "\n",
        "        x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
        "        tf.summary.image('training_images', x_image, step=step, max_outputs=3)\n",
        "\n",
        "    return loss_value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 학습 루프 (Mini-batch)\n",
        "- 총 10000 스텝 학습\n",
        "- 100 스텝마다 현재 정확도, 손실 출력\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "executionInfo": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Step 0] Training Accuracy: 0.1400, Loss: 2.3115\n",
            "WARNING:tensorflow:From C:\\Users\\LSJ\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function train_step at 0x000001FBD9078CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function train_step at 0x000001FBD9078CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[Step 100] Training Accuracy: 0.9000, Loss: 0.4529\n",
            "[Step 200] Training Accuracy: 0.9000, Loss: 0.2788\n",
            "[Step 300] Training Accuracy: 0.8800, Loss: 0.3283\n",
            "[Step 400] Training Accuracy: 0.9200, Loss: 0.1986\n",
            "[Step 500] Training Accuracy: 0.9000, Loss: 0.3468\n",
            "[Step 600] Training Accuracy: 0.9400, Loss: 0.1285\n",
            "[Step 700] Training Accuracy: 0.9400, Loss: 0.1067\n",
            "[Step 800] Training Accuracy: 0.9800, Loss: 0.1255\n",
            "[Step 900] Training Accuracy: 0.9800, Loss: 0.1365\n",
            "[Step 1000] Training Accuracy: 0.9800, Loss: 0.0491\n",
            "[Step 1100] Training Accuracy: 1.0000, Loss: 0.0288\n",
            "[Step 1200] Training Accuracy: 0.9600, Loss: 0.1173\n",
            "[Step 1300] Training Accuracy: 1.0000, Loss: 0.0326\n",
            "[Step 1400] Training Accuracy: 0.9600, Loss: 0.1034\n",
            "[Step 1500] Training Accuracy: 1.0000, Loss: 0.0139\n",
            "[Step 1600] Training Accuracy: 0.9800, Loss: 0.1095\n",
            "[Step 1700] Training Accuracy: 1.0000, Loss: 0.0211\n",
            "[Step 1800] Training Accuracy: 0.9800, Loss: 0.0339\n",
            "[Step 1900] Training Accuracy: 0.9800, Loss: 0.1485\n"
          ]
        }
      ],
      "source": [
        "num_steps = 2000\n",
        "\n",
        "for i in range(num_steps):\n",
        "    batch_x, batch_y = next(train_data_iter)\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        y_pred_temp, logits_temp = CNN_model(batch_x)\n",
        "        train_loss = cross_entropy_loss(logits_temp, batch_y)\n",
        "        train_acc  = compute_accuracy(y_pred_temp, batch_y)\n",
        "        print(f\"[Step {i}] Training Accuracy: {train_acc.numpy():.4f}, Loss: {train_loss.numpy():.4f}\")\n",
        "\n",
        "    # 학습 진행\n",
        "    loss_val = train_step(CNN_model, batch_x, batch_y, step=i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. 학습 완료 후 테스트 정확도 측정 및 TensorBoard에 기록"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "executionInfo": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "최종 테스트 정확도: 0.9853\n"
          ]
        }
      ],
      "source": [
        "# 최종 테스트 정확도 계산\n",
        "y_pred_test, logits_test = CNN_model(x_test)\n",
        "test_acc = compute_accuracy(y_pred_test, y_test)\n",
        "print(f\"최종 테스트 정확도: {test_acc.numpy():.4f}\")\n",
        "\n",
        "# 텐서보드에 테스트 정확도 기록\n",
        "final_step = num_steps\n",
        "with test_summary_writer.as_default():\n",
        "    tf.summary.scalar('test_accuracy', test_acc, step=final_step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "1bc00020",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 34472), started 0:02:21 ago. (Use '!kill 34472' to kill it.)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-cdb6bf63344ec50b\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-cdb6bf63344ec50b\");\n",
              "          const url = new URL(\"http://localhost\");\n",
              "          const port = 6006;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%tensorboard --logdir ./tensorboard_log"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "7.1-mnist_classification_using_cnn_with_tensorboard홍길동.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
