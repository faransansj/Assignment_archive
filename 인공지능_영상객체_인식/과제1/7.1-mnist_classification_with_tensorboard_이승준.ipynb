{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwNa2AbrZ-Gr"
   },
   "source": [
    "# 예제: CNN을 이용한 MNIST 숫자 분류\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YjhDFwiUrR4g"
   },
   "source": [
    "CNN을 이용한 MNIST 숫자분류 실습을 하겠습니다.\n",
    "\n",
    "먼저 텐서플로를 임포트해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "6iuMn-PJZzFo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version:  2.10.1\n",
      "Keras version:  2.10.0\n",
      "Python version:  3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "# 텐서플로 라이브러리를 임포트 합니다.\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "print(\"Tensorflow version: \", tf.__version__)   #2.18.0 as of 2025.04.08\n",
    "print(\"Keras version: \", tf.keras.__version__)  #3.8.0 as of 2025.04.08\n",
    "print(\"Python version: \", sys.version)          #3.11.11 as of 2025.04.08\n",
    "\n",
    "# TensorBoard 로그 설정\n",
    "import datetime\n",
    "log_dir = \"./tensorboard_log/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_summary_writer = tf.summary.create_file_writer(log_dir + \"/train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ARZr5sESrbfd"
   },
   "source": [
    "다음에는 MNIST 데이터를 케라스 내장 데이터셋에서 다운로드 합니다.\n",
    "\n",
    "다운로드한 이미지는 딥러닝 학습에 적합한 구조로 전처리를 해줘야 하는데, 먼저 이미지를 float type으로 바꿔주고, 28*28 2차원 이미지를  784개 1차원 벡터로 flattenin합니다.\n",
    "그 후에, [0, 255]값을 갖는 데이터를 [0.0, 1.0]값으로 normalize해주면 이미지 데이터 x의 전처리 과정이 마무리됩니다. 레이블 데이터 y값은 one-hot-encoding을 적용해줍니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "wF8srjU8aUM6"
   },
   "outputs": [],
   "source": [
    "# MNIST 데이터를 다운로드 합니다.\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "# 이미지들을 float32 데이터 타입으로 변경합니다.\n",
    "x_train, x_test = x_train.astype('float32'), x_test.astype('float32')\n",
    "# 28*28 형태의 이미지를 784차원으로 1*784로 flattening 합니다.\n",
    "x_train, x_test = x_train.reshape([-1, 784]), x_test.reshape([-1, 784])\n",
    "# [0, 255] 사이의 값을 [0, 1]사이의 값으로 Normalize합니다.\n",
    "x_train, x_test = x_train / 255., x_test / 255.\n",
    "# 레이블 데이터에 one-hot encoding을 적용합니다.\n",
    "y_train, y_test = tf.one_hot(y_train, depth=10), tf.one_hot(y_test, depth=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMGeBY50r8eY"
   },
   "source": [
    "다음으로는 6만개 데이터를 한꺼번에 메모리에 읽어서 처리하기에는 메모리 오버플로우 위험이 있기 때문에, 미니 배치로 쪼개서 트레이닝을 진행하기 위해 6만개를 무작위로 섞어서 50개로 쪼개는 작업을 진행합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3TzS0EtjaZDL"
   },
   "outputs": [],
   "source": [
    "# tf.data API를 이용해서 데이터를 섞고 batch 형태로 가져옵니다.\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.repeat().shuffle(60000).batch(50)\n",
    "train_data_iter = iter(train_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8UKANjYsO18"
   },
   "source": [
    "이제 tf.keras.model API를 이용해서 매우 간단한 CNN모델의 class를 정의해줍니다.\n",
    "\n",
    "이 CNN구조는 2개의 conv 레이어와 2개의 fully connected layer를 사용했는데, 맨처음 논문으로 발표된 CNN구조인 Alexnet이 5개의 conv레이어와 3개의 fully connected layer를 사용했고 그 후에 더 발전된 CNN구조들은 수십에서 수백개의 레이어를 사용했으므로, 여기 예제코드에서 정의된 구조는 매우 간소화된 CNN모델이라고 생각하시면 됩니다.\n",
    "\n",
    "첫번째 컨브 레이어는 32개의 5x5 filter를 사용하고, stride=1, padding 은 입력 이미지와 같은 사이즈가 되도록 채우게 하고, activation function은 ReLU로 하겠다고 선언했습니다.\n",
    "그 다음에는 맥스 풀링을 정의했는데, 2x2 filter size로 stride=2로 정의했으니까 출력 피처맵 사이즈는 입력보다 절반 사이즈가 될 것입니다.\n",
    "\n",
    "두번째 컨브 레이어와 풀링 레이어 정의에서는 64개의 5x5 filter로 컨볼루션을 하고, 2x2 filter로 맥스 풀링을 하는데, 패딩이나 activation함수는 이전 레이어와 동일하게 사용합니다.\n",
    "\n",
    "그 후에는 케라스의 flattening함수를 사용해서 flattening을 진행해줍니다. Flattening은 맨처음 CNN의 구조를 설명할 때에 잠깐 이야기했었는데, N개의 2차원 피처맵들을 1차원으로 쭉 펴주는 작업으로 이해하면 됩니다.\n",
    "\n",
    "케라스 라이브러리를 이용해서 레이어들의 정의가 끝나면, 아래쪽에서 데이터 플로우를 정의하는데,\n",
    "  \n",
    "\n",
    "1.   28x28입력 이미지에 32개 필터를 사용하기 위해서 1x28x28x1로 reshape해주고,\n",
    "2.   첫번째 컨브를 거치면 32개의 28x28 피처맵이 나오고,\n",
    "3. 맥스 풀링을 거치면 피처맵이 절반인 14x14로 줄어들고,\n",
    "4. 두번째 레이어의 컨브를 거치면 64개의 14x14 피처맵이 나오고,\n",
    "5. 맥스 풀링을 거치면 피처맵이 절반 사이즈로 줄어서 64개의 7x7 피처맵들이 됩니다.\n",
    "6. 이 피처맵들을 flattening을 하게 되면, 7x7x64, 즉 3136개의 노드로 바뀌게 됩니다.\n",
    "7. 3136개의 피처들은 fully connected layer-1에서 1024개로 매핑이 되고,\n",
    "8. 1024개는 다시 10개의 숫자 이미지를 의미하는 10개의 로짓으로 매핑이 됩니다.\n",
    "9. 로짓값에 소프트맥스 함수를 적용하면 숫자 예측값이 나오게 됩니다.\n",
    "\n",
    "이 CNN 클래스의 return값으로는 소프트맥스를 적용한 y_pred 예측값뿐 아니라, 소프트맥스를 적용하기 전의 로지트값도 같이 리턴하도록 정의했는데, 이유는 조금 있다가 설명하겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "GxvnBhYFaac1"
   },
   "outputs": [],
   "source": [
    "# tf.keras.Model을 이용해서 CNN 모델을 정의합니다.\n",
    "class CNN(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    super(CNN, self).__init__()\n",
    "    # 첫번째 Convolution Layer\n",
    "    # 5x5 Kernel Size를 가진 32개의 Filter를 적용합니다.\n",
    "    self.conv_layer_1 = tf.keras.layers.Conv2D(filters=32, kernel_size=5, strides=1, padding='same', activation='relu')\n",
    "    self.pool_layer_1 = tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=2)\n",
    "\n",
    "    # 두번째 Convolutional Layer\n",
    "    # 5x5 Kernel Size를 가진 64개의 Filter를 적용합니다.\n",
    "    self.conv_layer_2 = tf.keras.layers.Conv2D(filters=64, kernel_size=5, strides=1, padding='same', activation='relu')\n",
    "    self.pool_layer_2 = tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=2)\n",
    "\n",
    "    # Fully Connected Layer\n",
    "    # 7x7 크기를 가진 64개의 activation map을 1024개의 특징들로 변환합니다.\n",
    "    self.flatten_layer = tf.keras.layers.Flatten()\n",
    "    self.fc_layer_1 = tf.keras.layers.Dense(1024, activation='relu')\n",
    "\n",
    "    # Output Layer\n",
    "    # 1024개의 특징들(feature)을 10개의 클래스-one-hot encoding으로 표현된 숫자 0~9-로 변환합니다.\n",
    "    self.output_layer = tf.keras.layers.Dense(10, activation=None)\n",
    "\n",
    "  def call(self, x):\n",
    "    # MNIST 데이터를 3차원 형태로 reshape합니다. MNIST 데이터는 grayscale 이미지기 때문에 3번째차원(컬러채널)의 값은 1입니다.\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1])    # 28x28x1 -> 1x28x28x1\n",
    "    h_conv1 = self.conv_layer_1(x_image)        # 1x28x28x1 -> 28x28x32\n",
    "    h_pool1 = self.pool_layer_1(h_conv1)        # 28x28x32 -> 14x14x32\n",
    "    h_conv2 = self.conv_layer_2(h_pool1)        # 14x14x32 -> 14x14x64\n",
    "    h_pool2 = self.pool_layer_2(h_conv2)        # 14x14x64 -> 7x7x64\n",
    "    h_pool2_flat = self.flatten_layer(h_pool2)  # 7x7x64(3136) -> 3136\n",
    "    h_fc1 = self.fc_layer_1(h_pool2_flat)       # 3136 -> 1024\n",
    "    logits = self.output_layer(h_fc1)           # 1024 -> 10\n",
    "    y_pred = tf.nn.softmax(logits)\n",
    "\n",
    "    return y_pred, logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yidxCN8wtlBT"
   },
   "source": [
    "분류 문제 영역에서 손실함수로는 크로스 엔트로피를 많이 사용하는데, 크로스 엔터로피 손실함수 정의에서는 tf.nn라이브러리에서 내장하고 있는 softmax_cross_entropy_with_logits라는 함수를 사용해서 더 간단하게 코드를 구현했습니다.\n",
    "\n",
    "이 때에 첫번째 인자값으로는 y-pred 예측값을 사용하면 안되고, 꼭 로지트값을 사용해야 하는데, 로지트값을 넣어주면 함수 내부에서 자동으로 소프트맥스를 적용한 후에 크로스엔트로피를 계산해줍니다.\n",
    "\n",
    " 예전 실습할 때에, 이 함수를 사용하지 않고, 크로스 엔트로피 함수를 정의한 적이 있는데, 이보다 코드가 상당히 복잡해집니다. 두번째 인자인 참값 y는 one-hot-encoding된 참값 레이블입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "POZZx4UGagHE"
   },
   "outputs": [],
   "source": [
    "# cross-entropy 손실 함수를 정의합니다.\n",
    "def cross_entropy_loss(logits, y):\n",
    "  return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNDjewNdt440"
   },
   "source": [
    "옵티마이저로는 아담 옵티마이저를 선언했습니다. 이 때에 러닝레이트는 1e-4라는 표현을 사용했는데, 이것은 10^-4, 즉 0.0001이라는 의미입니다. 이렇게 숫자를 표현하는 방식을 scientific notation이라고 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "LfXCA5TQakR-"
   },
   "outputs": [],
   "source": [
    "# 최적화를 위한 Adam 옵티마이저를 정의합니다.\n",
    "optimizer = tf.optimizers.Adam(1e-4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3n4KFaGt_S2"
   },
   "source": [
    "\n",
    "다음으로 최적화 학습을 진행할 train_step함수를 정의합니다. 많이 반복해서 나왔던 대로, loss손실함수 값을 trainable_variable들로 미분한 후에, 이 그래디언트 값들로 trainiable_variable들을 업데이트 해주는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "C9aACWocanSR"
   },
   "outputs": [],
   "source": [
    "def train_step(model, x, y, step):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred, logits = model(x)\n",
    "        loss = cross_entropy_loss(logits, y)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', loss, step=step)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmjV5omFuDbo"
   },
   "source": [
    "다음에는 학습이 끝나고 모델의 정확도를 측정해주는 함수입니다.\n",
    "\n",
    "Tf.argmax는 최대값이 나오는 위치를 가르쳐주는 것인데, 참값 y는 one-hot-encoding되어 있으니까 본인에 해당되는 레이블이 있는 위치만 1이고 나머지는 0으로 되어 있는 벡터일 것이고, y_pred는 소프트맥스 결과니까 레이블의 확률을 나타내는 벡터일 것입니다. 그래서, argmax 최대값의 위치가 같다면 제대로 예측한 것이 되는 것입니다. Tf.equal은 두개의 텐서를 비교해서 같은 위치는 true, 틀린 위치는 false로 출력해주는 함수입니다.\n",
    "이 값을 tf.cast함수로 float type으로 바꾼 후에, tf.reduce_mean 함수로 평균값을 구해주면 0부터 1 사이 값이 나오게 되고, 1에 가까울수록 정확도가 100%에 가깝게 됩니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ysKJfn_OaqW3"
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(y_pred, y):\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_YrutHLBuX5P"
   },
   "source": [
    "이제 CNN 모델 클래스의 인스턴스를 선언해주고, 실제 학습을 시작합니다.\n",
    "\n",
    "Mini-batch training을 위해 50개씩 쪼개 놓은 60000개 데이터에 대해,순차적으로 10000번의 학습을 수행합니다.\n",
    "10000번의 Mini-batch 학습을 수행하는 도중, 100번째마다 평균 손실함수값을 표시해줍니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "SveskJs0aukW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Accuracy: 0.0800, Loss: 2.3096\n",
      "Step 100, Accuracy: 0.9400, Loss: 0.3730\n",
      "Step 200, Accuracy: 0.9000, Loss: 0.4198\n",
      "Step 300, Accuracy: 0.9600, Loss: 0.1149\n",
      "Step 400, Accuracy: 0.9400, Loss: 0.1301\n",
      "Step 500, Accuracy: 0.9400, Loss: 0.1504\n",
      "Step 600, Accuracy: 0.9200, Loss: 0.1913\n",
      "Step 700, Accuracy: 0.9600, Loss: 0.0707\n",
      "Step 800, Accuracy: 0.9000, Loss: 0.3588\n",
      "Step 900, Accuracy: 1.0000, Loss: 0.0613\n",
      "Step 1000, Accuracy: 0.9600, Loss: 0.0993\n",
      "Step 1100, Accuracy: 0.9800, Loss: 0.0973\n",
      "Step 1200, Accuracy: 0.9600, Loss: 0.0840\n",
      "Step 1300, Accuracy: 1.0000, Loss: 0.0248\n",
      "Step 1400, Accuracy: 0.9800, Loss: 0.0745\n",
      "Step 1500, Accuracy: 0.9600, Loss: 0.0958\n",
      "Step 1600, Accuracy: 1.0000, Loss: 0.0320\n",
      "Step 1700, Accuracy: 0.9800, Loss: 0.0534\n",
      "Step 1800, Accuracy: 0.9800, Loss: 0.0644\n",
      "Step 1900, Accuracy: 0.9600, Loss: 0.1891\n",
      "Step 2000, Accuracy: 1.0000, Loss: 0.0171\n",
      "Step 2100, Accuracy: 0.9600, Loss: 0.0868\n",
      "Step 2200, Accuracy: 0.9600, Loss: 0.1387\n",
      "Step 2300, Accuracy: 0.9600, Loss: 0.0803\n",
      "Step 2400, Accuracy: 0.9800, Loss: 0.0277\n",
      "Step 2500, Accuracy: 1.0000, Loss: 0.0159\n",
      "Step 2600, Accuracy: 1.0000, Loss: 0.0056\n",
      "Step 2700, Accuracy: 1.0000, Loss: 0.0146\n",
      "Step 2800, Accuracy: 1.0000, Loss: 0.0064\n",
      "Step 2900, Accuracy: 0.9800, Loss: 0.0347\n",
      "Step 3000, Accuracy: 0.9800, Loss: 0.0328\n",
      "Step 3100, Accuracy: 0.9800, Loss: 0.0880\n",
      "Step 3200, Accuracy: 1.0000, Loss: 0.0178\n",
      "Step 3300, Accuracy: 1.0000, Loss: 0.0134\n",
      "Step 3400, Accuracy: 0.9800, Loss: 0.0431\n",
      "Step 3500, Accuracy: 1.0000, Loss: 0.0134\n",
      "Step 3600, Accuracy: 0.9800, Loss: 0.0241\n",
      "Step 3700, Accuracy: 0.9800, Loss: 0.0370\n",
      "Step 3800, Accuracy: 0.9800, Loss: 0.0693\n",
      "Step 3900, Accuracy: 0.9800, Loss: 0.0391\n",
      "Step 4000, Accuracy: 1.0000, Loss: 0.0159\n",
      "Step 4100, Accuracy: 1.0000, Loss: 0.0215\n",
      "Step 4200, Accuracy: 1.0000, Loss: 0.0187\n",
      "Step 4300, Accuracy: 0.9800, Loss: 0.0664\n",
      "Step 4400, Accuracy: 1.0000, Loss: 0.0092\n",
      "Step 4500, Accuracy: 0.9800, Loss: 0.0787\n",
      "Step 4600, Accuracy: 1.0000, Loss: 0.0071\n",
      "Step 4700, Accuracy: 1.0000, Loss: 0.0230\n",
      "Step 4800, Accuracy: 0.9600, Loss: 0.1634\n",
      "Step 4900, Accuracy: 0.9800, Loss: 0.0600\n",
      "Step 5000, Accuracy: 1.0000, Loss: 0.0141\n",
      "Step 5100, Accuracy: 0.9800, Loss: 0.0240\n",
      "Step 5200, Accuracy: 0.9800, Loss: 0.1055\n",
      "Step 5300, Accuracy: 1.0000, Loss: 0.0046\n",
      "Step 5400, Accuracy: 1.0000, Loss: 0.0137\n",
      "Step 5500, Accuracy: 1.0000, Loss: 0.0047\n",
      "Step 5600, Accuracy: 0.9800, Loss: 0.0195\n",
      "Step 5700, Accuracy: 0.9600, Loss: 0.0887\n",
      "Step 5800, Accuracy: 0.9800, Loss: 0.0308\n",
      "Step 5900, Accuracy: 0.9800, Loss: 0.1103\n",
      "Step 6000, Accuracy: 1.0000, Loss: 0.0143\n",
      "Step 6100, Accuracy: 0.9800, Loss: 0.0347\n",
      "Step 6200, Accuracy: 1.0000, Loss: 0.0074\n",
      "Step 6300, Accuracy: 0.9600, Loss: 0.0518\n",
      "Step 6400, Accuracy: 1.0000, Loss: 0.0071\n",
      "Step 6500, Accuracy: 0.9800, Loss: 0.0663\n",
      "Step 6600, Accuracy: 1.0000, Loss: 0.0079\n",
      "Step 6700, Accuracy: 1.0000, Loss: 0.0026\n",
      "Step 6800, Accuracy: 0.9800, Loss: 0.0375\n",
      "Step 6900, Accuracy: 0.9800, Loss: 0.0463\n",
      "Step 7000, Accuracy: 0.9800, Loss: 0.0623\n",
      "Step 7100, Accuracy: 1.0000, Loss: 0.0124\n",
      "Step 7200, Accuracy: 1.0000, Loss: 0.0140\n",
      "Step 7300, Accuracy: 1.0000, Loss: 0.0099\n",
      "Step 7400, Accuracy: 1.0000, Loss: 0.0071\n",
      "Step 7500, Accuracy: 1.0000, Loss: 0.0088\n",
      "Step 7600, Accuracy: 0.9800, Loss: 0.0465\n",
      "Step 7700, Accuracy: 0.9800, Loss: 0.0204\n",
      "Step 7800, Accuracy: 1.0000, Loss: 0.0032\n",
      "Step 7900, Accuracy: 0.9800, Loss: 0.0487\n",
      "Step 8000, Accuracy: 1.0000, Loss: 0.0045\n",
      "Step 8100, Accuracy: 0.9800, Loss: 0.0497\n",
      "Step 8200, Accuracy: 1.0000, Loss: 0.0043\n",
      "Step 8300, Accuracy: 1.0000, Loss: 0.0027\n",
      "Step 8400, Accuracy: 1.0000, Loss: 0.0084\n",
      "Step 8500, Accuracy: 1.0000, Loss: 0.0149\n",
      "Step 8600, Accuracy: 1.0000, Loss: 0.0055\n",
      "Step 8700, Accuracy: 0.9800, Loss: 0.0536\n",
      "Step 8800, Accuracy: 0.9800, Loss: 0.0387\n",
      "Step 8900, Accuracy: 0.9400, Loss: 0.1227\n",
      "Step 9000, Accuracy: 1.0000, Loss: 0.0021\n",
      "Step 9100, Accuracy: 0.9800, Loss: 0.0960\n",
      "Step 9200, Accuracy: 0.9800, Loss: 0.0335\n",
      "Step 9300, Accuracy: 0.9800, Loss: 0.0166\n",
      "Step 9400, Accuracy: 1.0000, Loss: 0.0011\n",
      "Step 9500, Accuracy: 1.0000, Loss: 0.0015\n",
      "Step 9600, Accuracy: 1.0000, Loss: 0.0004\n",
      "Step 9700, Accuracy: 1.0000, Loss: 0.0023\n",
      "Step 9800, Accuracy: 1.0000, Loss: 0.0086\n",
      "Step 9900, Accuracy: 1.0000, Loss: 0.0033\n"
     ]
    }
   ],
   "source": [
    "CNN_model = CNN()\n",
    "\n",
    "for i in range(10000):\n",
    "    batch_x, batch_y = next(train_data_iter)\n",
    "    y_pred, logits = CNN_model(batch_x)\n",
    "    train_accuracy = compute_accuracy(y_pred, batch_y)\n",
    "    loss_value = cross_entropy_loss(logits, batch_y)\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Step {i}, Accuracy: {train_accuracy:.4f}, Loss: {loss_value:.4f}\")\n",
    "    train_step(CNN_model, batch_x, batch_y, step=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28RTedfHueRM"
   },
   "source": [
    "모든 학습이 끝나면 테스트 데이터로 학습의 정확도를 계산해서 출력합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "REsGMEWFa3we"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도(Accuracy): 0.991300\n"
     ]
    }
   ],
   "source": [
    "# 학습이 끝나면 학습된 모델의 정확도를 출력합니다.\n",
    "# 약 99% 정확도가 출력됨.\n",
    "print(\"정확도(Accuracy): %f\" % compute_accuracy(CNN_model(x_test)[0], y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tzdt6XpDMRxy"
   },
   "source": [
    "# 과제: tensorboard 시각화의 추가\n",
    "예제코드 4.4에서 배운 tensorboard 시각화 기능을 위의 코드에 추가해보기\n",
    "\n",
    "\n",
    "\n",
    "1.   create_file_writer함수로 train 및 test시의 텐서보드 summary 정보들을 저장할 폴더 경로를 설정하고 FileWriter를 선언(train_summary_writer와 test_sumary_writer).\n",
    "2.   train_step 함수 정의에 매 step마다 텐서보드 로그에 tf.summary.scalar로 'loss'값을 기록하고, tf.summary.image로 'training image'를 기록하는 코드 추가.\n",
    "3. 학습이 끝난후 모델 정확도를 계산하는 compute_accuracy 함수 정의에 'accuracy'를 기록하는 코드 추가.\n",
    "4. 10000번 step의 최적화를 실행할 때에 train_summary_writer에 과정이 기록되도록 함.\n",
    "5. 학습이 끝난후 compute_accuracy 계산시에 test_summary_writer에 accuracy가 기록되도록 함.\n",
    "6. '%load_ext tensorboard' 명령어를 통해 Colab tensorboard extension을 불러옴.\n",
    "7. '%tensorboard --logdir ./tensorboard_log' 명령어를 통해 학습과정을 시각화 해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ead734b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f10f32199ca3eb88\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f10f32199ca3eb88\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./tensorboard_log/20250412-224247"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20250412-224134', '20250412-224247', 'test', 'train']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"./tensorboard_log/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuClass": "premium",
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
