{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 7.1 - MNIST Classification using CNN with TensorBoard\n",
        "\n",
        "## 순서\n",
        "1. 라이브러리 임포트 및 TensorBoard 설정\n",
        "2. MNIST 데이터 불러오기 및 전처리\n",
        "3. CNN 모델 정의 (tf.keras.Model)\n",
        "4. 손실함수, 옵티마이저, 정확도 함수 정의\n",
        "5. TensorBoard 로그 생성\n",
        "6. train_step 함수에서 텐서보드 로그 기록\n",
        "7. 학습 루프 (Mini-batch)\n",
        "8. 최종 테스트 정확도 기록 및 TensorBoard에서 시각화\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost/"
        },
        "executionInfo": {},
        "id": "import-libraries"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.10.1\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import datetime, os\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "print(f\"TensorFlow version: {tf.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. MNIST 데이터 불러오기 및 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "executionInfo": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 784)\n",
            "y_train shape: (60000, 10)\n"
          ]
        }
      ],
      "source": [
        "# MNIST 데이터를 다운로드 하고, 정규화\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test  = x_test.astype('float32')\n",
        "\n",
        "x_train = x_train.reshape([-1, 784])\n",
        "x_test  = x_test.reshape([-1, 784])\n",
        "\n",
        "x_train = x_train / 255.\n",
        "x_test  = x_test / 255.\n",
        "\n",
        "y_train = tf.one_hot(y_train, depth=10)\n",
        "y_test  = tf.one_hot(y_test,  depth=10)\n",
        "\n",
        "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_data = train_data.repeat().shuffle(60000).batch(50)\n",
        "train_data_iter = iter(train_data)\n",
        "\n",
        "print(f\"x_train shape: {x_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. CNN 모델 정의 (tf.keras.Model 사용)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "executionInfo": {}
      },
      "outputs": [],
      "source": [
        "class CNN(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # 첫 번째 Convolution Layer: 5x5 Kernel, 32개 Filter\n",
        "        self.conv_layer_1 = tf.keras.layers.Conv2D(\n",
        "            filters=32, kernel_size=5, strides=1, padding='same', activation='relu')\n",
        "        self.pool_layer_1 = tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=2)\n",
        "\n",
        "        # 두 번째 Convolution Layer: 5x5 Kernel, 64개 Filter\n",
        "        self.conv_layer_2 = tf.keras.layers.Conv2D(\n",
        "            filters=64, kernel_size=5, strides=1, padding='same', activation='relu')\n",
        "        self.pool_layer_2 = tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=2)\n",
        "\n",
        "        # Flatten + Fully connected\n",
        "        self.flatten_layer = tf.keras.layers.Flatten()\n",
        "        self.fc_layer_1    = tf.keras.layers.Dense(1024, activation='relu')\n",
        "        self.output_layer  = tf.keras.layers.Dense(10, activation=None)\n",
        "\n",
        "    def call(self, x):\n",
        "        # x: (batch, 784) -> reshape to (batch,28,28,1)\n",
        "        x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
        "\n",
        "        h_conv1 = self.conv_layer_1(x_image)   # -> (batch, 28,28,32)\n",
        "        h_pool1 = self.pool_layer_1(h_conv1)   # -> (batch, 14,14,32)\n",
        "\n",
        "        h_conv2 = self.conv_layer_2(h_pool1)   # -> (batch, 14,14,64)\n",
        "        h_pool2 = self.pool_layer_2(h_conv2)   # -> (batch, 7,7,64)\n",
        "\n",
        "        h_pool2_flat = self.flatten_layer(h_pool2)  # -> (batch, 7*7*64=3136)\n",
        "        h_fc1 = self.fc_layer_1(h_pool2_flat)       # -> (batch, 1024)\n",
        "\n",
        "        logits = self.output_layer(h_fc1)           # -> (batch, 10)\n",
        "        y_pred = tf.nn.softmax(logits, axis=1)\n",
        "        return y_pred, logits\n",
        "\n",
        "# 모델 인스턴스 생성\n",
        "CNN_model = CNN()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 손실함수, 옵티마이저, 정확도 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "executionInfo": {}
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def cross_entropy_loss(logits, y):\n",
        "    return tf.reduce_mean(\n",
        "        tf.nn.softmax_cross_entropy_with_logits(\n",
        "            logits=logits, labels=y)\n",
        "    )\n",
        "\n",
        "optimizer = tf.optimizers.Adam(1e-4)\n",
        "\n",
        "@tf.function\n",
        "def compute_accuracy(y_pred, y):\n",
        "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. TensorBoard 로그 디렉토리 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "executionInfo": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_log_dir: tensorboard_log\\train\n",
            "test_log_dir : tensorboard_log\\test\n"
          ]
        }
      ],
      "source": [
        "log_dir = \"tensorboard_log\"  # 로그 저장 경로\n",
        "train_log_dir = os.path.join(log_dir, \"train\")\n",
        "test_log_dir  = os.path.join(log_dir, \"test\")\n",
        "\n",
        "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
        "test_summary_writer  = tf.summary.create_file_writer(test_log_dir)\n",
        "\n",
        "print(f\"train_log_dir: {train_log_dir}\")\n",
        "print(f\"test_log_dir : {test_log_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. train_step 함수에서 텐서보드 로그 기록"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "executionInfo": {}
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(model, x, y, step):\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred, logits = model(x)\n",
        "        loss_value = cross_entropy_loss(logits, y)\n",
        "\n",
        "    gradients = tape.gradient(loss_value, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    # 텐서보드에 loss 기록\n",
        "    with train_summary_writer.as_default():\n",
        "        tf.summary.scalar('training_loss', loss_value, step=step)\n",
        "\n",
        "        x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
        "        tf.summary.image('training_images', x_image, step=step, max_outputs=3)\n",
        "\n",
        "    return loss_value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 학습 루프 (Mini-batch)\n",
        "- 총 10000 스텝 학습\n",
        "- 100 스텝마다 현재 정확도, 손실 출력\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "executionInfo": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Step 0] Training Accuracy: 0.1200, Loss: 2.2989\n",
            "WARNING:tensorflow:From C:\\Users\\LSJ\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function train_step at 0x0000022D625A5C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function train_step at 0x0000022D625A5C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[Step 100] Training Accuracy: 0.9000, Loss: 0.3742\n",
            "[Step 200] Training Accuracy: 0.8800, Loss: 0.5047\n",
            "[Step 300] Training Accuracy: 0.9200, Loss: 0.2510\n",
            "[Step 400] Training Accuracy: 0.8600, Loss: 0.4335\n",
            "[Step 500] Training Accuracy: 0.9400, Loss: 0.1257\n",
            "[Step 600] Training Accuracy: 0.9600, Loss: 0.0849\n",
            "[Step 700] Training Accuracy: 0.9800, Loss: 0.0654\n",
            "[Step 800] Training Accuracy: 1.0000, Loss: 0.0731\n",
            "[Step 900] Training Accuracy: 0.9600, Loss: 0.1095\n",
            "[Step 1000] Training Accuracy: 0.9600, Loss: 0.1150\n",
            "[Step 1100] Training Accuracy: 0.9800, Loss: 0.0390\n",
            "[Step 1200] Training Accuracy: 0.9800, Loss: 0.0445\n",
            "[Step 1300] Training Accuracy: 0.9800, Loss: 0.1015\n",
            "[Step 1400] Training Accuracy: 1.0000, Loss: 0.0147\n",
            "[Step 1500] Training Accuracy: 1.0000, Loss: 0.0389\n",
            "[Step 1600] Training Accuracy: 0.9800, Loss: 0.0451\n",
            "[Step 1700] Training Accuracy: 0.9600, Loss: 0.0818\n",
            "[Step 1800] Training Accuracy: 1.0000, Loss: 0.0093\n",
            "[Step 1900] Training Accuracy: 1.0000, Loss: 0.0211\n",
            "[Step 2000] Training Accuracy: 0.9800, Loss: 0.1134\n",
            "[Step 2100] Training Accuracy: 1.0000, Loss: 0.0300\n",
            "[Step 2200] Training Accuracy: 0.9800, Loss: 0.0327\n",
            "[Step 2300] Training Accuracy: 0.9000, Loss: 0.1443\n",
            "[Step 2400] Training Accuracy: 0.9600, Loss: 0.1643\n",
            "[Step 2500] Training Accuracy: 0.9800, Loss: 0.0565\n",
            "[Step 2600] Training Accuracy: 1.0000, Loss: 0.0064\n",
            "[Step 2700] Training Accuracy: 1.0000, Loss: 0.0265\n",
            "[Step 2800] Training Accuracy: 1.0000, Loss: 0.0292\n",
            "[Step 2900] Training Accuracy: 0.9800, Loss: 0.0317\n",
            "[Step 3000] Training Accuracy: 0.9400, Loss: 0.1767\n",
            "[Step 3100] Training Accuracy: 0.9800, Loss: 0.1231\n",
            "[Step 3200] Training Accuracy: 1.0000, Loss: 0.0100\n",
            "[Step 3300] Training Accuracy: 1.0000, Loss: 0.0086\n",
            "[Step 3400] Training Accuracy: 1.0000, Loss: 0.0047\n",
            "[Step 3500] Training Accuracy: 0.9800, Loss: 0.0771\n",
            "[Step 3600] Training Accuracy: 1.0000, Loss: 0.0132\n",
            "[Step 3700] Training Accuracy: 1.0000, Loss: 0.0116\n",
            "[Step 3800] Training Accuracy: 1.0000, Loss: 0.0058\n",
            "[Step 3900] Training Accuracy: 0.9800, Loss: 0.0446\n",
            "[Step 4000] Training Accuracy: 1.0000, Loss: 0.0457\n",
            "[Step 4100] Training Accuracy: 1.0000, Loss: 0.0368\n",
            "[Step 4200] Training Accuracy: 0.9800, Loss: 0.0289\n",
            "[Step 4300] Training Accuracy: 1.0000, Loss: 0.0099\n",
            "[Step 4400] Training Accuracy: 0.9600, Loss: 0.0594\n",
            "[Step 4500] Training Accuracy: 0.9800, Loss: 0.0411\n",
            "[Step 4600] Training Accuracy: 0.9800, Loss: 0.0170\n",
            "[Step 4700] Training Accuracy: 0.9800, Loss: 0.0416\n",
            "[Step 4800] Training Accuracy: 0.9800, Loss: 0.0245\n",
            "[Step 4900] Training Accuracy: 0.9800, Loss: 0.0481\n",
            "[Step 5000] Training Accuracy: 1.0000, Loss: 0.0092\n",
            "[Step 5100] Training Accuracy: 1.0000, Loss: 0.0092\n",
            "[Step 5200] Training Accuracy: 1.0000, Loss: 0.0173\n",
            "[Step 5300] Training Accuracy: 1.0000, Loss: 0.0167\n",
            "[Step 5400] Training Accuracy: 0.9800, Loss: 0.1310\n",
            "[Step 5500] Training Accuracy: 1.0000, Loss: 0.0350\n",
            "[Step 5600] Training Accuracy: 0.9000, Loss: 0.1950\n",
            "[Step 5700] Training Accuracy: 1.0000, Loss: 0.0139\n",
            "[Step 5800] Training Accuracy: 0.9600, Loss: 0.0740\n",
            "[Step 5900] Training Accuracy: 0.9800, Loss: 0.0550\n",
            "[Step 6000] Training Accuracy: 1.0000, Loss: 0.0015\n",
            "[Step 6100] Training Accuracy: 1.0000, Loss: 0.0162\n",
            "[Step 6200] Training Accuracy: 0.9800, Loss: 0.0191\n",
            "[Step 6300] Training Accuracy: 1.0000, Loss: 0.0158\n",
            "[Step 6400] Training Accuracy: 0.9800, Loss: 0.0517\n",
            "[Step 6500] Training Accuracy: 0.9400, Loss: 0.0747\n",
            "[Step 6600] Training Accuracy: 0.9800, Loss: 0.0618\n",
            "[Step 6700] Training Accuracy: 0.9800, Loss: 0.0319\n",
            "[Step 6800] Training Accuracy: 0.9800, Loss: 0.0484\n",
            "[Step 6900] Training Accuracy: 1.0000, Loss: 0.0134\n",
            "[Step 7000] Training Accuracy: 0.9800, Loss: 0.0335\n",
            "[Step 7100] Training Accuracy: 1.0000, Loss: 0.0151\n",
            "[Step 7200] Training Accuracy: 1.0000, Loss: 0.0140\n",
            "[Step 7300] Training Accuracy: 0.9600, Loss: 0.1538\n",
            "[Step 7400] Training Accuracy: 1.0000, Loss: 0.0023\n",
            "[Step 7500] Training Accuracy: 0.9800, Loss: 0.0353\n",
            "[Step 7600] Training Accuracy: 1.0000, Loss: 0.0053\n",
            "[Step 7700] Training Accuracy: 1.0000, Loss: 0.0074\n",
            "[Step 7800] Training Accuracy: 1.0000, Loss: 0.0030\n",
            "[Step 7900] Training Accuracy: 1.0000, Loss: 0.0014\n",
            "[Step 8000] Training Accuracy: 0.9800, Loss: 0.1454\n",
            "[Step 8100] Training Accuracy: 0.9800, Loss: 0.0355\n",
            "[Step 8200] Training Accuracy: 1.0000, Loss: 0.0036\n",
            "[Step 8300] Training Accuracy: 1.0000, Loss: 0.0188\n",
            "[Step 8400] Training Accuracy: 1.0000, Loss: 0.0077\n",
            "[Step 8500] Training Accuracy: 1.0000, Loss: 0.0038\n",
            "[Step 8600] Training Accuracy: 1.0000, Loss: 0.0181\n",
            "[Step 8700] Training Accuracy: 1.0000, Loss: 0.0105\n",
            "[Step 8800] Training Accuracy: 1.0000, Loss: 0.0010\n",
            "[Step 8900] Training Accuracy: 0.9800, Loss: 0.0285\n",
            "[Step 9000] Training Accuracy: 1.0000, Loss: 0.0226\n",
            "[Step 9100] Training Accuracy: 0.9600, Loss: 0.0961\n",
            "[Step 9200] Training Accuracy: 0.9800, Loss: 0.0523\n",
            "[Step 9300] Training Accuracy: 1.0000, Loss: 0.0038\n",
            "[Step 9400] Training Accuracy: 1.0000, Loss: 0.0063\n",
            "[Step 9500] Training Accuracy: 1.0000, Loss: 0.0238\n",
            "[Step 9600] Training Accuracy: 1.0000, Loss: 0.0087\n",
            "[Step 9700] Training Accuracy: 1.0000, Loss: 0.0005\n",
            "[Step 9800] Training Accuracy: 1.0000, Loss: 0.0058\n",
            "[Step 9900] Training Accuracy: 1.0000, Loss: 0.0023\n"
          ]
        },
        {
          "ename": "ResourceExhaustedError",
          "evalue": "Graph execution error:\n\nDetected at node 'gradient_tape/cnn/conv2d_1/Conv2D/Conv2DBackpropInput' defined at (most recent call last):\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3172, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\LSJ\\AppData\\Local\\Temp/ipykernel_2652/2384447595.py\", line 13, in <module>\n      loss_val = train_step(CNN_model, batch_x, batch_y, step=i)\n    File \"C:\\Users\\LSJ\\AppData\\Local\\Temp/ipykernel_2652/3782460843.py\", line 7, in train_step\n      gradients = tape.gradient(loss_value, model.trainable_variables)\nNode: 'gradient_tape/cnn/conv2d_1/Conv2D/Conv2DBackpropInput'\nOOM when allocating tensor with shape[36,196,800] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node gradient_tape/cnn/conv2d_1/Conv2D/Conv2DBackpropInput}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_step_2733018]",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2652/2384447595.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# 학습 진행\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mloss_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCNN_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/cnn/conv2d_1/Conv2D/Conv2DBackpropInput' defined at (most recent call last):\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 677, in start\n      self.io_loop.start()\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n      self._run_once()\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n      handle._run()\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 457, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 446, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 353, in dispatch_shell\n      await result\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 648, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 353, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2901, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2947, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3172, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3364, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"c:\\Users\\LSJ\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\LSJ\\AppData\\Local\\Temp/ipykernel_2652/2384447595.py\", line 13, in <module>\n      loss_val = train_step(CNN_model, batch_x, batch_y, step=i)\n    File \"C:\\Users\\LSJ\\AppData\\Local\\Temp/ipykernel_2652/3782460843.py\", line 7, in train_step\n      gradients = tape.gradient(loss_value, model.trainable_variables)\nNode: 'gradient_tape/cnn/conv2d_1/Conv2D/Conv2DBackpropInput'\nOOM when allocating tensor with shape[36,196,800] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node gradient_tape/cnn/conv2d_1/Conv2D/Conv2DBackpropInput}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_step_2733018]"
          ]
        }
      ],
      "source": [
        "num_steps = 10000\n",
        "\n",
        "for i in range(num_steps):\n",
        "    batch_x, batch_y = next(train_data_iter)\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        y_pred_temp, logits_temp = CNN_model(batch_x)\n",
        "        train_loss = cross_entropy_loss(logits_temp, batch_y)\n",
        "        train_acc  = compute_accuracy(y_pred_temp, batch_y)\n",
        "        print(f\"[Step {i}] Training Accuracy: {train_acc.numpy():.4f}, Loss: {train_loss.numpy():.4f}\")\n",
        "\n",
        "    # 학습 진행\n",
        "    loss_val = train_step(CNN_model, batch_x, batch_y, step=i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. 학습 완료 후 테스트 정확도 측정 및 TensorBoard에 기록"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "executionInfo": {}
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "최종 테스트 정확도: 0.1594\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'num_steps' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_38340/1976371040.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# 텐서보드에 테스트 정확도 기록\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mfinal_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtest_summary_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test_accuracy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfinal_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'num_steps' is not defined"
          ]
        }
      ],
      "source": [
        "# 최종 테스트 정확도 계산\n",
        "y_pred_test, logits_test = CNN_model(x_test)\n",
        "test_acc = compute_accuracy(y_pred_test, y_test)\n",
        "print(f\"최종 테스트 정확도: {test_acc.numpy():.4f}\")\n",
        "\n",
        "# 텐서보드에 테스트 정확도 기록\n",
        "final_step = num_steps\n",
        "with test_summary_writer.as_default():\n",
        "    tf.summary.scalar('test_accuracy', test_acc, step=final_step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1bc00020",
      "metadata": {},
      "outputs": [],
      "source": [
        "%tensorboard --logdir ./tensorboard_log"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "7.1-mnist_classification_using_cnn_with_tensorboard홍길동.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
